---
title: Testing Transfermarkt's Squad Values
subtitle: |
  Using Bundesliga staff costs to evaluate Transfermarkt's squad values as a
  proxy for Bundesliga club spending
description-meta: |
  Using the Bundesliga's financial reports to test Transfermarkt's squad values
  as a proxy for squad costs.
date: 2025-05-07
image: ball.webp
image-alt: |
  A Derbystar Bundesliga match ball sitting on the turf of a football pitch.
categories: [Football Analytics, Statistics, Machine Learning, R]
bibliography: references.bib
---

```{r}
#| label: setup
#| output: false
#| code-fold: true
#| code-summary: 'Setup Code (Click to Expand)'

# import packages
suppressPackageStartupMessages({
  library(dplyr)
  library(gt)
  library(ggplot2)
  library(tidymodels)
})

# setup fonts
sysfonts::font_add_google("Poppins")
sysfonts::font_add_google("Lora")
showtext::showtext_auto()

# set plot theme
# inspired by https://github.com/z3tt/TidyTuesday/blob/main/R/2020_31_PalmerPenguins.Rmd
theme_set(theme_minimal(base_size = 20, base_family = "Poppins")) +
  theme_update(
    panel.grid.major = element_line(color = "grey90", linewidth = .4),
    panel.grid.minor = element_blank(),
    panel.spacing.x = unit(.65, units = "cm"),
    panel.spacing.y = unit(.3, units = "cm"),
    axis.title.x = element_text(
      color = "grey30",
      margin = margin(t = 5),
      size = rel(1.05)
    ),
    axis.title.y = element_text(
      color = "grey30",
      margin = margin(r = 5),
      size = rel(1.05)
    ),
    axis.text = element_text(color = "grey50", size = rel(1)),
    # axis.text.x = element_text(angle = 30, vjust = 1, hjust = .75),
    axis.ticks = element_line(color = "grey90", linewidth = .4),
    axis.ticks.length = unit(.2, "lines"),
    legend.position = "top",
    legend.title = element_blank(),
    legend.text = element_text(size = rel(.9)),
    legend.box.margin = margin(0, 0, -10, 0),
    legend.key.width = unit(1, units = "cm"),
    plot.title = element_text(
      hjust = 0,
      color = "black",
      family = "Lora",
      size = rel(1.5),
      margin = margin(t = 5, b = 5)
    ),
    plot.subtitle = element_text(
      hjust = 0,
      color = "grey30",
      family = "Lora",
      lineheight = 0.5,
      size = rel(1.1),
      margin = margin(5, 0, 5, 0)
    ),
    plot.title.position = "plot",
    plot.caption = element_text(
      color = "grey50",
      size = rel(0.8),
      hjust = 1,
      margin = margin(10, 0, 0, 0)
    ),
    plot.caption.position = "plot",
    plot.margin = margin(rep(10, 4)),
    strip.text = element_text(size = rel(1), margin = margin(0, 0, 5, 0)),
    strip.clip = "off"
  )

# set table theme
tbl_theme <-
  function(data, width = 100, alignment = "center") {
    data |>
      tab_source_note(
        source_note = "Source: DFL & Transfermarkt Via {worldfootballR}"
      ) |>
      tab_options(
        footnotes.marks = "standard",
        footnotes.spec_ref = "^xb",
        footnotes.spec_ftr = "(x)",
        table.width = pct(width),
        table.align = alignment,
        table.font.names = "Poppins"
      ) |>
      tab_style(
        style = cell_text(align = "left"),
        locations = list(cells_source_notes(), cells_footnotes())
      )
  }

# load data
buli_resources <-
  readr::read_rds(
    here::here(
      "blog",
      "2025-05-07-comparing-transfermarkt-squad-values-staff-costs",
      "data",
      "buli_resources.rds"
    )
  )
```

Last year, I wrote a [blog post](https://paulrjohnson.net/blog/analysing-money-in-football/) that modeled the effect that money has on outcomes in the Europe's five biggest football leagues. The key explanatory variable in my model was Transfermarkt's squad values, serving as a proxy for a club's financial clout. While research has shown that Transfermarkt's player market values have strong associations with transfer fees [@herm2014; @muller2017; @coates2022], the existing literature regarding player salaries is promising but the volume is much more limited [@prockl2018]. Further, research has also identified that player values vary in predictive value by league [@muller2017; @coates2022]. All this considered, I concluded that Transfermarkt's squad market values were an effective proxy for squad spending[^Spending]. But what if I was wrong?

I used a proxy for the same reason everyone uses a proxy — because I didn't have data for the variables I would have otherwise used. Unlike many other cases, I think my own laziness is the missing data culprit. I think the best way to capture financial clout is using squad costs. This could either be **just** a club's wage spending, or it could be all spending on the squad (wages + transfer fees). While this data isn't exactly readily available, I'm pretty sure I could track down the wage spending from annual financial reports. So I took the easy way out.

A few weeks ago, [Ansgar Wolsing](https://bsky.app/profile/ansgarw.bsky.social) made me aware of the Deutsche Fussball Liga (DFL)'s [published reports](https://www.dfl.de/de/hintergrund/lizenzierungsverfahren/finanzkennzahlen-der-proficlubs/) detailing the annual financial accounts for every club in the Bundesliga (and 2. Bundesliga). Those accounts include each club's spending on "staff costs", which is all staff, including the playing squad.

Never one to miss an opportunity to make _content_, I went right to work and grabbed six seasons of data, from 2017/18 to 2022/23. Now, we can find out whether or not Transfermarkt's squad values are a reasonable proxy for the data I was too lazy to go looking for (until someone basically dropped it in my lap). Lesbeavenue!

[^Spending]:

Which is itself effectively a proxy for a club's financial resources, since the assumption is that clubs will spend close to the maximum they can on their squad.

## Exploring the Data

While the majority of clubs report their staff costs on a season-basis, there are some that report staff costs for the financial year. In those cases, the costs don't perfectly align to a single season, but I don't think the change in costs from season-to-season is large enough to be a huge concern.

However, I did have to drop Frankfurt's 2022/23 season from the data. This was because Frankfurt were one of the teams that have been reporting their costs for the financial year, but in 2023 they made the switch to reporting costs over a season. In order to line their reports up, this meant the 2023 report is just the costs for the first six months of 2023 (so that the following season is on the correct schedule). I did think about doubling the Frankfurt figures, and I'm sure this would be approximately right in reality, but it feels a little too icky so I just dropped them.

Another discrepancy in the data occurs in the 2021/22 season. The figures published in 2024 refer to the 2022/23 season, but the reports are organised by division, with all teams in the Bundesliga in the 2024/25 season in one report, and the same for the 2. Bundesliga. I have absolutely no idea why the figures are organised like this, but I'm sure there's some logic that I'm just too stupid to see. For the most part it was just an inconvenience, creating a lot more work for me to pull the costs together for the right teams in the right season. In 2022/23, however, Paderborn were relegated from the Bundesliga, followed by another relegation down to the 3. Liga in 2023/24. The trouble is, while the top two tiers in Germany are governed by the DFL, the third tier is governed by the DFB. Paderborn's consecutive relegations mean that they aren't included in these reports. It's despicable. The real victim here is me. No one has been hurt more by Paderborn plummeting down the German football pyramid.

### The Value-Cost Gap (Difference)

To start with, it's probably worth comparing the squad values and staff costs directly, to get some sense of what we are working with. I will start by capturing the difference between the two and exploring how this figure varies across the dataset.

If we take the difference between squad values and staff costs, plotted below, we see that the gap between the two is pretty large, with squad values usually the larger of the two (though occasionally the difference is negative because a team's staff costs are higher than their squad values).

```{r}
#| label: scale-function
#| code-fold: true
#| code-summary: 'Helper Function Code (Click to Expand)'

scale_euros <-
  function(axes = c("both", "x", "y"), expand = c(0.01, 0)) {
    scales <- list()

    if (axes[1] %in% c("both", "x")) {
      scales <- append(
        scales,
        list(
          scale_x_continuous(
            labels = scales::label_number(
              scale_cut = scales::cut_short_scale(),
              prefix = "€"
            ),
            expand = expand
          )
        )
      )
    }

    if (axes[1] %in% c("both", "y")) {
      scales <- append(
        scales,
        list(
          scale_y_continuous(
            labels = scales::label_number(
              scale_cut = scales::cut_short_scale(),
              prefix = "€"
            ),
            expand = expand
          )
        )
      )
    }

    return(scales)
  }
```

```{r}
#| label: difference-distribution
#| code-fold: true
#| code-summary: 'Plot Code (Click to Expand)'

buli_resources |>
  mutate(diff = squad_value - staff_cost) |>
  ggplot(aes(x = diff)) +
  geom_histogram(color = "#343a40", bins = 30) +
  geom_hline(yintercept = 0, colour = "#343a40") +
  scale_euros(axes = "x") +
  labs(
    title = "Median Difference Squad Value vs. Staff Cost in the Bundesliga",
    subtitle = stringr::str_wrap(
      glue::glue(
        "Distribution of differences between club squad values and staff costs ",
        "per season in the Bundesliga from 2017/18 to 2022/23."
      ),
      width = 93
    ),
    x = "Value Difference\n(Squad Value - Staff Cost)",
    y = NULL,
    caption = "Visualisation: Paul Johnson | Data: DFL & Transfermarkt via {worldfootballR}"
  )
```

The fact there is a big difference between the two values is not a problem. Of course they are different. They are not claiming to be the same thing. This doesn't render squad values useless as a proxy, as long as squad values is directionally approximate with staff cost.

The question is whether there is any bias between the two across the Bundesliga. One way of looking at this is taking the average difference in squad values and staff costs by team, below, to see how the differences tend to differ by club. When calculating the average differences I've used the median since it is very skewed.

```{r}
#| label: tbl-team-difference
#| tbl-cap: Median Difference Squad Values vs. Staff Cost
#| code-fold: true
#| code-summary: 'Table Code (Click to Expand)'

buli_resources |>
  mutate(diff = squad_value - staff_cost) |>
  add_count(team) |>
  filter(n >= 3) |>
  summarise(club_diff = median(diff), .by = team) |>
  arrange(desc(club_diff)) |>
  gt(rowname_col = "team") |>
  cols_label(
    club_diff = md("Value Difference<br>(Squad Value - Staff Cost)")
  ) |>
  fmt_currency(
    columns = club_diff,
    currency = "EUR",
    suffixing = TRUE,
    decimals = 1
  ) |>
  cols_align(align = "center", columns = club_diff) |>
  tab_style(
    style = list(cell_fill(color = "#f8f9fa")),
    locations = cells_body(rows = everything())
  ) |>
  tbl_theme()
```

I've filtered for teams that appear in three or more seasons in the data. I've mostly done this to reduce the list down a bit, but it also takes out the noisiest observations (though all are obviously pretty small sample, since the max is just six).

When you compare the average difference between market value and squad costs between clubs, it is pretty obvious that the differences are a function of the quality of the team, or perhaps of the resources available to teams. I suspect this is probably picking up an issue with the squad values data. Squad values are updated regularly and will be responsive to player (and team) performances. Good teams play better and this leads to better teams seeing their values increase.

Another explanation could be that this is just a product of scales. The squad values are generally larger than the staff costs, but perhaps they are a certain percentage higher, on average, and for teams with larger staff costs that's inherently going to mean a bigger difference.

I also considered the possibility that this might be driven by underlying temporal differences. The difference doesn't appear to change all that much from season-to-season, with perhaps the exception being 2017/18. I think it's reasonable to assume there is not a significant temporal component going on here.

### When Value Meets Reality (Correlation)

Initial exploration suggests that squad values are an effective proxy for staff costs (which are themselves a proxy for squad spending). The correlation between the two variables paints an even clearer picture. There is a **`{r} round(cor(buli_resources$staff_cost, buli_resources$squad_value), 2)`** correlation between squad values and staff costs, which is pretty remarkable.

When we visualise the association between the two, below, this further illustrates how closely tied together they are.

```{r}
#| label: costs-by-value
#| code-fold: true
#| code-summary: 'Plot Code (Click to Expand)'

buli_resources |>
  ggplot(aes(x = staff_cost, y = squad_value)) +
  geom_point(alpha = 0.5, size = 2, colour = "#343a40") +
  geom_smooth(
    method = lm,
    colour = "#026E99",
    # fill = "#026E99",
    linewidth = 1.2,
    alpha = 0.15
  ) +
  scale_euros() +
  labs(
    title = "Staff Costs vs. Squad Market Values in the Bundesliga",
    subtitle = stringr::str_wrap(
      glue::glue(
        "Relationship between staff costs and squad values in the Bundesliga ",
        "from 2017/18 - 2022/23."
      ),
      width = 93
    ),
    x = "Staff Cost",
    y = "Squad Value",
    caption = "Visualisation: Paul Johnson | Data: DFL & Transfermarkt Via {worldfootballR}"
  )
```

The relationship between staff costs and squad values is incredibly clean. It is clearly linear, and any variance is only minimal.

There doesn't appear to be anything particularly systematic about the variance. At the lower end of staff costs it looks like squad values are a little undervalued, but the reverse is true as it increases. At the top end of staff costs, the squad values are all slightly undervalued. I think the top end of the staff costs will all be Bayern Munich (I'm not sure how much this matters).

All this paints a pretty clear picture. Squad values seem to be a very good approximation of staff costs.

## Comparing Predictive Performance

The final test of squad values as an appropriate proxy for staff costs is to compare their predictive performance.

```{r}
#| label: outcome-diffs
#| fig-height: 7
#| code-fold: true
#| code-summary: 'Plot Code (Click to Expand)'

buli_resources |>
  tidyr::pivot_longer(
    cols = c(pts, xgd, gd),
    names_to = "outcome",
    values_to = "outcome_value"
  ) |>
  tidyr::pivot_longer(
    cols = c(squad_value, staff_cost),
    names_to = "metric",
    values_to = "metric_value"
  ) |>
  mutate(
    outcome = case_when(
      outcome == "pts" ~ "Points",
      outcome == "gd" ~ "Goal Difference",
      outcome == "xgd" ~ "xG Difference",
      .default = outcome
    ),
    metric = if_else(metric == "squad_value", "Squad Value", "Staff Cost")
  ) |>
  ggplot(aes(x = metric_value, y = outcome_value)) +
  geom_point(alpha = 0.5, size = 1.2, color = "#343a40") +
  geom_smooth(
    method = lm,
    formula = y ~ log(x),
    colour = "#026E99",
    # fill = "#026E99",
    se = TRUE,
    linewidth = 1,
    alpha = 0.2
  ) +
  facet_grid(
    rows = vars(outcome),
    cols = vars(metric),
    scales = "free",
    switch = "y"
  ) +
  scale_euros(axes = "x") +
  labs(
    title = "Bundesliga Outcomes vs. Squad Value & Staff Cost",
    subtitle = stringr::str_wrap(
      glue::glue(
        "Impact of squad values and staff costs on performance metrics and ",
        "outcomes —— points, goal difference, and xG difference —— in the ",
        "Bundesliga across the 2017/18 - 2022/23 seasons."
      ),
      width = 93
    ),
    x = NULL,
    y = NULL,
    caption = "Visualisation: Paul Johnson | Data: DFL & Transfermarkt Via {worldfootballR}"
  ) +
  theme(
    panel.spacing = unit(1, "lines"),
    strip.placement = "outside",
    # panel.spacing.x = unit(.3, units = "cm"),
    axis.text.x = element_text(angle = 30, vjust = 1, hjust = 0.8)
  )
```

### XGBoost Models

```{r}
#| label: fit-functions
#| code-fold: true
#| code-summary: 'Helper Functions Code (Click to Expand)'

# preprocessing function
preprocess_data <- function(recipe_obj) {
  recipe_obj |>
    step_log(any_of(c("squad_value", "staff_cost"))) |>
    step_novel(all_nominal_predictors()) |>
    step_dummy(all_nominal_predictors()) |>
    step_zv()
}

# target/predictor combination recipes function
create_recipes <- function(targets, predictors) {
  combos <- tidyr::crossing(target = targets, predictor = predictors)

  # set seed
  furrr_opts <- furrr::furrr_options(seed = 42)

  # create recipe list
  recipes <- furrr::future_pmap(
    combos,
    function(target, predictor) {
      recipe(
        formula = as.formula(glue::glue(
          "{target} ~ {predictor} + season + team"
        )),
        data = train
      ) |>
        preprocess_data()
    },
    .options = furrr_opts
  )

  # name list elements
  names(recipes) <-
    furrr::future_pmap_chr(
      combos,
      ~ glue::glue("{..1}_{..2}"),
      .options = furrr_opts
    )

  recipes
}
```

```{r}
#| label: train-and-tune-models
#| code-fold: true
#| code-summary: 'Model Code (Click to Expand)'
#| cache: true

# set seed for reproducibility
set.seed(42)

# set up parallel backend
future::plan(future::multisession, workers = parallel::detectCores() - 1)

# split train/test data and specify folds
splits <- initial_split(buli_resources, prop = 0.8)
train <- training(splits)
test <- testing(splits)
folds <- vfold_cv(train, v = 10, repeats = 5)

# generate recipes
recipes <- create_recipes(
  targets = c("pts", "gd", "xgd"),
  predictors = c("squad_value", "staff_cost")
)

# xgboost model spec (with tuning)
xgb_spec <- boost_tree(
  trees = 1200,
  learn_rate = 0.005,
  tree_depth = tune(),
  loss_reduction = tune(),
  sample_size = tune(),
  stop_iter = tune()
) |>
  set_engine("xgboost") |>
  set_mode("regression")

# workflow set from recipes and model
wf_sets <- workflow_set(
  preproc = recipes,
  models = list(xgb = xgb_spec)
)

# tuning control
ctrl <- finetune::control_sim_anneal(
  save_pred = TRUE,
  parallel_over = "everything",
  save_workflow = TRUE,
  verbose = TRUE
)

# tune all workflows
tuned_results <- workflow_map(
  wf_sets,
  fn = "tune_sim_anneal",
  control = ctrl,
  metrics = metric_set(rmse, rsq),
  resamples = folds,
  seed = 42
)

# stop future plan
future::plan(future::sequential)
```

I won't bother to walk through the code to fit the models since that isn't the focus of the post here, but I've fit and tuned XGBoost models for each of the three outcomes that I used in my original model — points, goal difference, xG difference — with season and team included as features, as well as squad values or staff costs. In total, this results in six different models.

The goal isn't to go to great lengths to fit perfect models. I've done a little tuning just for the hell of it, but the focus is really on just comparing the performance of the squad values and staff costs models.

```{r}
#| label: eval-functions
#| code-fold: true
#| code-summary: 'Helper Functions Code (Click to Expand)'

# select the best parameters
select_best_model <- function(results, model_id) {
  results |>
    extract_workflow_set_result(model_id) |>
    select_best(metric = "rmse")
}

# finalize and refit on full training data
finalize_and_fit_model <- function(results, model_id, data_split) {
  best_params <- select_best_model(results, model_id)

  results |>
    extract_workflow(model_id) |>
    finalize_workflow(best_params) |>
    last_fit(split = data_split, metrics = metric_set(rmse, rsq))
}

# extract test performance metrics
get_test_metrics <- function(results, model_id, data_split) {
  finalize_and_fit_model(results, model_id, data_split) |>
    collect_metrics()
}
```

```{r}
#| label: best-params
#| include: false

# get best hyperparameters for each model
best_params <- purrr::map(
  tuned_results$wflow_id,
  ~ select_best_model(tuned_results, .x)
)
names(best_params) <- tuned_results$wflow_id

best_params
```

```{r}
#| label: tbl-model-performance
#| tbl-cap: Predictive Performance of Squad Values & Staff Costs
#| code-fold: true
#| code-summary: 'Table Code (Click to Expand)'

# get test performance for all models
summary_table <-
  tuned_results |>
  mutate(
    test_metrics = map(wflow_id, ~ get_test_metrics(tuned_results, .x, splits)),
    feature_set = if_else(
      stringr::str_detect(wflow_id, "_squad"),
      "Squad Value",
      "Staff Costs"
    ),
    outcome = case_when(
      stringr::str_starts(wflow_id, "pts") ~ "Points",
      stringr::str_starts(wflow_id, "gd") ~ "Goal Difference",
      stringr::str_starts(wflow_id, "xgd") ~ "xG Difference"
    ),
    outcome = forcats::fct(
      outcome,
      levels = c("Points", "Goal Difference", "xG Difference")
    )
  ) |>
  arrange(outcome) |>
  unnest(test_metrics) |>
  pivot_wider(names_from = .metric, values_from = .estimate) |>
  select(feature_set, outcome, rmse, rsq)

# display metrics table
summary_table |>
  gt(groupname_col = "feature_set", rowname_col = "outcome") |>
  cols_label(
    rmse = "RMSE",
    rsq = html("R<sup>2</sup>")
  ) |>
  fmt_number(
    columns = c(rmse, rsq),
    decimals = 2,
    drop_trailing_zeros = TRUE
  ) |>
  cols_align(align = "left", columns = outcome) |>
  cols_align(align = "center", columns = c(rmse, rsq)) |>
  tab_spanner(label = "Evaluation Metrics", columns = c(rmse, rsq)) |>
  tab_style(
    style = list(cell_text(weight = "bold")),
    locations = cells_column_spanners()
  ) |>
  tab_style(
    style = list(cell_text(weight = "bold")),
    locations = cells_row_groups()
  ) |>
  tbl_theme()
```

These results do broadly demonstrate how well aligned staff costs and squad values are, but the fact that squad values consistently outperform staff costs is interesting. The squad values models have marginally better root mean squared errors (RMSEs), but they significantly outperform the staff costs models according to R<sup>2</sup>.

It's worth noting that the models are tuned on RMSE, so the variance in R<sup>2</sup> is perhaps a function of this. What is most important is that the performance is generally only a little better, according to the metric being tuned.

I think the only reasonable conclusion is that this is because some performance bias is getting baked in, but the fact the performance is only slightly improved is a good sign.

## How Reliable are Squad Values?

There is very little difference between the two, and while it does seem like squad values are a little biased by performance, I don't think it is making such a difference that it's a big problem. It's just something to be aware of if using them as a proxy for something like squad costs.

Perhaps I am underestimating how much of a difference it makes that I'm using staff costs here?

## Acknowledgments {.appendix}

Preview image by [Tobias Rehbein](https://unsplash.com/@tobiasrehbein) on [Unsplash](https://unsplash.com/photos/a-soccer-ball-sitting-on-top-of-a-lush-green-field-CZ_HwDtvEus).

## Support {.appendix}

If you enjoyed this blog post and would like to support my work, you can [buy me a coffee or a beer or give me a tip](https://www.buymeacoffee.com/paulj1989) as a thank you.
