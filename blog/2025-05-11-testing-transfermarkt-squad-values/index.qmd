---
title: Testing Transfermarkt's Squad Market Values
subtitle: |
  Get in losers, we're going validating.
description-meta: |
  Using data from the DFL's financial reports for all Bundesliga clubs to evaluate
  whether Transfermarkt's squad market values are an adequate proxy for squad costs.
date: 2025-05-11
image: ball.webp
image-alt: |
  A Derbystar Bundesliga match ball sitting on the turf of a football pitch.
categories: [Football Analytics, Statistics, Machine Learning, R]
bibliography: references.bib
---

```{r}
#| label: setup
#| output: false
#| code-fold: true
#| code-summary: 'Setup Code (Click to Expand)'

# import packages
suppressPackageStartupMessages({
  library(dplyr)
  library(gt)
  library(ggplot2)
  library(tidymodels)
})

# setup fonts
sysfonts::font_add_google("Poppins")
sysfonts::font_add_google("Lora")
showtext::showtext_auto()

# set plot theme
# inspired by https://github.com/z3tt/TidyTuesday/blob/main/R/2020_31_PalmerPenguins.Rmd
theme_set(theme_minimal(base_size = 20, base_family = "Poppins")) +
  theme_update(
    panel.grid.major = element_line(color = "grey90", linewidth = .4),
    panel.grid.minor = element_blank(),
    panel.spacing.x = unit(.65, units = "cm"),
    panel.spacing.y = unit(.3, units = "cm"),
    axis.title.x = element_text(
      color = "grey30",
      margin = margin(t = 5),
      size = rel(1.05),
      lineheight = 0.55
    ),
    axis.title.y = element_text(
      color = "grey30",
      margin = margin(r = 5),
      size = rel(1.05),
      lineheight = 0.55
    ),
    axis.text = element_text(color = "grey50", size = rel(1)),
    axis.ticks = element_line(color = "grey90", linewidth = .4),
    axis.ticks.length = unit(.2, "lines"),
    legend.position = "top",
    legend.title = element_blank(),
    legend.text = element_text(size = rel(.9)),
    legend.box.margin = margin(0, 0, -10, 0),
    legend.key.width = unit(1, units = "cm"),
    plot.title = element_text(
      hjust = 0,
      color = "black",
      family = "Lora",
      size = rel(1.5),
      margin = margin(t = 5, b = 5)
    ),
    plot.subtitle = element_text(
      hjust = 0,
      color = "grey30",
      family = "Lora",
      lineheight = 0.55,
      size = rel(1.1),
      margin = margin(5, 0, 15, 0)
    ),
    plot.title.position = "plot",
    plot.caption = element_text(
      color = "grey50",
      size = rel(0.8),
      hjust = 1,
      margin = margin(10, 0, 0, 0)
    ),
    plot.caption.position = "plot",
    plot.margin = margin(rep(10, 4)),
    strip.text = element_text(size = rel(1), margin = margin(0, 0, 5, 0)),
    strip.clip = "off"
  )

# set table theme
tbl_theme <-
  function(data, width = 100, alignment = "center") {
    data |>
      tab_source_note(
        source_note = "Source: DFL & Transfermarkt"
      ) |>
      tab_options(
        footnotes.marks = "standard",
        footnotes.spec_ref = "^i",
        footnotes.spec_ftr = "()",
        table.width = pct(width),
        table.align = alignment,
        table.font.names = "Poppins"
      ) |>
      tab_style(
        style = cell_text(align = "left"),
        locations = list(cells_source_notes(), cells_footnotes())
      )
  }

# load data
buli_resources <-
  readr::read_rds(
    here::here(
      "blog",
      "2025-05-11-testing-transfermarkt-squad-values",
      "data",
      "buli_resources.rds"
    )
  )
```

Last year, I wrote a [blog post](https://paulrjohnson.net/blog/analysing-money-in-football/) that modelled the effect that money has on outcomes in Europe's five biggest football leagues. The key explanatory variable in my model was Transfermarkt's squad market values. Squad value served as a proxy for a club's financial clout. The assumption was that clubs generally invest as much money in the team as possible, but data capturing the full extent of squad spending is challenging to source. Research shows Transfermarkt's player market values are strongly associated with transfer fees [@herm2014; @muller2017; @coates2022] and player salaries [@prockl2018], so I figured squad values would be an adequate proxy for squad spending. But what if I was wrong?

A little over a month ago, I was [made aware](https://bsky.app/profile/ansgarw.bsky.social/post/3lm2hgpgxfc2j) of the DFL's (Deutsche Fussball Liga) [financial reports](https://www.dfl.de/de/hintergrund/lizenzierungsverfahren/finanzkennzahlen-der-proficlubs/) detailing the annual accounts for every club in the Bundesliga (and 2. Bundesliga). The accounts include each club's "staff costs", which is the amount each club spends on wages for all employees (including but not limited to playing staff). I think this will should be a close approximation of squad wage spending[^Costs]. Never one to miss an opportunity to make _content_, I went to work and grabbed six seasons of data from 2017/18 to 2022/23. Now, we can determine whether Transfermarkt's squad values are a reasonable proxy for the data I was too lazy to go and find myself. And more importantly, we can find out if I was wrong[^Wrong].

[^Costs]:

Players and playing staff will make up the majority of staff costs for all clubs, and I think it is reasonable to assume that non-playing staff costs will be directly related to playing staff costs (bigger teams like Bayern Munich will have more non-playing employees).

[^Wrong]:

It is actually illegal to tell me I'm wrong.

## Exploring the Data

The data is pretty solid, but it comes with some caveats. While most clubs report their staff costs on a seasonal basis, some report staff costs for the financial year. In those cases, the costs don't perfectly align with a single season, but I don't think the change in costs from season to season is significant enough to be a huge concern. I also had to drop Frankfurt's 2022/23 season[^Frankfurt] and Paderborn's 2021/22 season[^Paderborn] from the data.

I'm not too worried that these caveats will cause any significant problems. Although the sample size is relatively small, the data seem sufficient for the question I'm trying to answer here.

[^Frankfurt]:

Frankfurt were one of the teams reporting their costs for the financial year, but in 2023, they switched to reporting costs over a season. To line their reports up, this meant the 2023 report is just the costs for the first six months of 2023 (so that the following season is on the correct schedule).

[^Paderborn]:

The figures published in 2024 refer to the 2022/23 season, but the reports are organised by division, with all teams in the Bundesliga in the 2024/25 season in one report and the same for the 2. Bundesliga. For the most part, this was just an inconvenience. In 2022/23, however, Paderborn were relegated from the Bundesliga, followed by another relegation down to the 3. Liga in 2023/24. The trouble is, while the top two tiers in Germany are governed by the DFL, the third tier is governed by the DFB. Paderborn's consecutive relegations mean that they aren't included in these reports. It's despicable. The real victim here is me.

### The Value-Cost Gap (Difference)

First, it's probably worth comparing the squad values and staff costs directly to understand what we are working with. I will start by capturing the difference between the two and exploring how this figure varies across the dataset.

Plotting the difference between squad value and staff costs below, we see that the gap between the two is sizeable, with squad value usually (but not always) larger.

```{r}
#| label: scale-function
#| code-fold: true
#| code-summary: 'Helper Function Code (Click to Expand)'

scale_euros <- function(axes = c("both", "x", "y"), expand = c(0.01, 0)) {
  # euro label with short scale
  label_euro <- scales::label_number(
    scale_cut = scales::cut_short_scale(),
    prefix = "€"
  )

  # return ggplot scales based on axis selection
  switch(
    axes[1],
    x = list(scale_x_continuous(labels = label_euro, expand = expand)),
    y = list(scale_y_continuous(labels = label_euro, expand = expand)),
    both = list(
      scale_x_continuous(labels = label_euro, expand = expand),
      scale_y_continuous(labels = label_euro, expand = expand)
    )
  )
}
```

```{r}
#| label: difference-distribution
#| fig-alt: |
#|    A histogram visualising the distribution of club value differences (squad
#|    market value minus staff costs) per season from 2017/18 to 2022/23. The
#|    distribution is right-skewed, peaking at around €50m with a long tail
#|    reaching over €500m.
#| code-fold: true
#| code-summary: 'Plot Code (Click to Expand)'

buli_resources |>
  mutate(diff = squad_value - staff_cost) |>
  ggplot(aes(x = diff)) +
  geom_histogram(color = "#343a40", bins = 25) +
  geom_hline(yintercept = 0, colour = "#343a40") +
  scale_euros(axes = "x") +
  labs(
    title = "Differences Between Squad Value & Staff Costs in the Bundesliga",
    subtitle = stringr::str_wrap(
      glue::glue(
        "The distribution of club value differences (squad value minus staff ",
        "costs) per season in the Bundesliga from 2017/18 to 2022/23."
      ),
      width = 95
    ),
    x = "Value Difference\n(Squad Value - Staff Costs)",
    y = NULL,
    caption = "Visualisation: Paul Johnson | Data: DFL & Transfermarkt"
  )
```

The difference between the two isn't an issue. Squad value and staff costs are different things. If they generally vary together, that will suffice.

It's also worth considering the team-level variance[^Time]. @tbl-team-difference shows the median difference between squad value and staff costs per season for clubs that have played three or more seasons in the data[^Filter].

```{r}
#| label: tbl-team-difference
#| tbl-cap: Median Value Differences in the Bundesliga from 2017/18 to 2022/23
#| code-fold: true
#| code-summary: 'Table Code (Click to Expand)'

buli_resources |>
  mutate(diff = squad_value - staff_cost) |>
  add_count(team) |>
  filter(n >= 3) |>
  summarise(club_diff = median(diff), .by = team) |>
  arrange(desc(club_diff)) |>
  gt(rowname_col = "team") |>
  cols_label(
    club_diff = md("Value Difference<br>(Squad Value - Staff Costs)")
  ) |>
  fmt_currency(
    columns = club_diff,
    currency = "EUR",
    suffixing = TRUE,
    decimals = 1
  ) |>
  cols_align(align = "center", columns = club_diff) |>
  tab_style(
    style = list(cell_fill(color = "#f8f9fa")),
    locations = cells_body(rows = everything())
  ) |>
  tbl_theme()
```

Looking at @tbl-team-difference, it is obvious that the differences are at least partially a function of the team's quality or the resources available to teams. This probably identifies an issue with Transfermarkt's values. Squad values are updated regularly and will be responsive to player (and team) performances. Good teams play better, leading to better teams seeing their values increase.

Another explanation could be that this is just a product of scales. The squad values are generally larger than the staff costs, but perhaps they are a certain percentage higher, on average, and for teams with higher staff costs, that's inherently going to mean a bigger difference.

[^Time]:

I also looked at variance over time. The difference doesn't appear to change much from season to season, with perhaps the exception being 2017/18. I think it's reasonable to assume there is not a significant temporal component going on here.

[^Filter]:

My main reason for filtering the data this way was to reduce the list of clubs included and make the table a little smaller. It also removes the noisiest observations (though all are obviously small samples since the maximum seasons are just six).

### When Value Meets Reality (Correlation)

If the differences between squad value and staff costs are a mixed bag, the correlation between the two paints a clearer picture. There is a `{r} round(cor(buli_resources$staff_cost, buli_resources$squad_value), 2)` correlation between squad value and staff costs, which is pretty remarkable.

When we visualise the association between the two below, it further illustrates how closely tied they are.

```{r}
#| label: costs-by-value
#| fig-alt: |
#|    A regression plot visualising the association between staff costs and squad
#|    value. The plot shows a positive linear association with relatively little
#|    variance.
#| code-fold: true
#| code-summary: 'Plot Code (Click to Expand)'

buli_resources |>
  ggplot(aes(x = staff_cost, y = squad_value)) +
  geom_point(alpha = 0.5, size = 2, colour = "#343a40") +
  geom_smooth(
    method = lm,
    colour = "#026E99",
    linewidth = 1.2,
    alpha = 0.15
  ) +
  scale_euros() +
  labs(
    title = "Squad Value by Staff Costs in the Bundesliga",
    subtitle = stringr::str_wrap(
      glue::glue(
        "The correlation between staff costs and squad value in the Bundesliga ",
        "from 2017/18 to 2022/23."
      ),
      width = 95
    ),
    x = "Staff Costs",
    y = "Squad Value",
    caption = "Visualisation: Paul Johnson | Data: DFL & Transfermarkt"
  )
```

The relationship is incredibly clean. It is clearly linear, and any variance is minimal. Squad values are undervalued at the lower end of staff costs, but the reverse is true, as it increases. At the top end of staff costs, the squad values are all slightly undervalued. Squad value seems to be an excellent approximation of staff costs from this perspective.

## Comparing Predictive Performance

The final test of squad value's validity as a proxy for staff costs is to compare how well both predict Bundesliga outcomes. To remain consistent with the original model, I will use the outcomes used in my original blog post—points, goal difference, and expected goal (xG) difference—all standardised using games played (so their value represents outcome value per game).

Squad value and staff costs are strongly correlated with all three league outcomes, as shown in @tbl-correlation.

```{r}
#| label: tbl-correlation
#| tbl-cap: Correlation Between Squad Value/Staff Costs & Bundesliga Outcomes
#| code-fold: true
#| code-summary: 'Table Code (Click to Expand)'

# compute correlations
correlation_table <- buli_resources |>
  select(squad_value, staff_cost, pts, gd, xgd) |>
  correlation::correlation(
    select = c("squad_value", "staff_cost"),
    select2 = c("pts", "gd", "xgd")
  ) |>
  as_tibble() |>
  mutate(
    feature_set = if_else(
      stringr::str_detect(Parameter1, "squad_"),
      "Squad Value",
      "Staff Costs"
    ),
    outcome = recode(
      Parameter2,
      pts = "Points",
      gd = "Goal Difference",
      xgd = "xG Difference",
      .default = Parameter2
    ),
    outcome = forcats::fct(
      outcome,
      levels = c("Points", "Goal Difference", "xG Difference")
    )
  ) |>
  select(feature_set, outcome, r)

# display correlation table
correlation_table |>
  gt(rowname_col = "outcome", groupname_col = "feature_set") |>
  cols_label(r = "Correlation") |>
  fmt_number(columns = r, decimals = 2, drop_trailing_zeros = TRUE) |>
  cols_align(align = "left", columns = outcome) |>
  cols_align(align = "center", columns = r) |>
  tab_style(
    # bold column spanners
    style = cell_text(weight = "bold"),
    locations = cells_column_spanners()
  ) |>
  tab_style(
    # bold group labels
    style = cell_text(weight = "bold"),
    locations = cells_row_groups()
  ) |>
  tbl_theme()
```

All three outcomes have stronger correlations with squad value than staff costs. The differences are relatively small, but they are consistent. However, the differences are barely perceptible when we plot the relationship between our two predictors and the Bundesliga outcomes below.

```{r}
#| label: outcome-diffs
#| fig-alt: |
#|    A faceted regression plot visualising the association between the predictors
#|    (squad value and staff cost) and the league outcomes (points, goal difference,
#|    and xG difference). There are a total of six plots, each showing a positive
#|    association, with both predictors log-transformed to fit a non-linear pattern
#|    in the data.
#| fig-height: 7
#| code-fold: true
#| code-summary: 'Plot Code (Click to Expand)'

buli_resources |>
  # reshape data to long format for outcomes and metrics
  pivot_longer(
    cols = c(pts, xgd, gd),
    names_to = "outcome",
    values_to = "outcome_value"
  ) |>
  pivot_longer(
    cols = c(squad_value, staff_cost),
    names_to = "metric",
    values_to = "metric_value"
  ) |>
  mutate(
    outcome = recode(
      outcome,
      pts = "Points",
      gd = "Goal Difference",
      xgd = "xG Difference",
      .default = outcome
    ),
    outcome = forcats::fct(
      outcome,
      levels = c("Points", "Goal Difference", "xG Difference")
    ),
    metric = if_else(metric == "squad_value", "Squad Value", "Staff Costs")
  ) |>
  ggplot(aes(x = metric_value, y = outcome_value)) +
  geom_point(alpha = 0.5, size = 1.2, color = "#343a40") +
  geom_smooth(
    # log-linear trend lines
    method = lm,
    formula = y ~ log(x),
    colour = "#026E99",
    se = TRUE,
    linewidth = 1,
    alpha = 0.2
  ) +
  facet_grid(
    # layout by outcome and metric
    rows = vars(outcome),
    cols = vars(metric),
    scales = "free",
    switch = "y"
  ) +
  scale_euros(axes = "x") +
  labs(
    title = "Bundesliga Outcomes by Squad Value & Staff Costs",
    subtitle = stringr::str_wrap(
      glue::glue(
        "Comparing squad value and staff costs' assocation with Bundesliga ",
        "outcomes—points, goal difference, and xG difference—from 2017/18 to ",
        "2022/23. Outcomes standardised by games."
      ),
      width = 93
    ),
    x = NULL,
    y = NULL,
    caption = "Visualisation: Paul Johnson | Data: DFL & Transfermarkt"
  ) +
  theme(
    panel.spacing = unit(1, "lines"),
    strip.placement = "outside",
    panel.spacing.x = unit(.3, "cm"),
    axis.text.x = element_text(angle = 30, vjust = 1, hjust = 0.8)
  )
```

The variance appears to be a little larger in the staff costs plots, particularly at around €100m, where the bulk of the observations are. Still, the difference is not obvious. I'm not sure I would have noticed the difference if I wasn't already aware of the slightly weaker correlation between staff costs and the league outcomes. Perhaps this is a me problem. Maybe I'm confessing my lack of attention to detail.

### XGBoost Models

```{r}
#| label: fit-functions
#| code-fold: true
#| code-summary: 'Helper Functions Code (Click to Expand)'

# preprocessing function
preprocess_data <- function(recipe_obj) {
  recipe_obj |>
    step_log(any_of(c("squad_value", "staff_cost"))) |>
    step_novel(all_nominal_predictors()) |>
    step_dummy(all_nominal_predictors()) |>
    step_zv()
}

# target/predictor combination recipes function
create_recipes <- function(targets, predictors) {
  combos <- crossing(target = targets, predictor = predictors)

  # set seed
  furrr_opts <- furrr::furrr_options(seed = 42)

  # create recipe list
  recipes <- furrr::future_pmap(
    combos,
    function(target, predictor) {
      recipe(
        formula = as.formula(glue::glue(
          "{target} ~ {predictor} + season + team"
        )),
        data = train
      ) |>
        preprocess_data()
    },
    .options = furrr_opts
  )

  # name list elements
  names(recipes) <-
    furrr::future_pmap_chr(
      combos,
      ~ glue::glue("{..1}_{..2}"),
      .options = furrr_opts
    )

  recipes
}
```

```{r}
#| label: train-and-tune-models
#| code-fold: true
#| code-summary: 'Model Code (Click to Expand)'
#| cache: true

# set seed for reproducibility
set.seed(42)

# set up parallel backend
future::plan(future::multisession, workers = parallel::detectCores() - 1)

# split train/test data and specify folds
splits <- initial_split(buli_resources, prop = 0.7)
train <- training(splits)
test <- testing(splits)
folds <- vfold_cv(train, v = 10, repeats = 5)

# generate recipes
recipes <- create_recipes(
  targets = c("pts", "gd", "xgd"),
  predictors = c("squad_value", "staff_cost")
)

# xgboost model spec (with tuning)
xgb_spec <- boost_tree(
  trees = 1200,
  learn_rate = 0.005,
  tree_depth = tune(),
  loss_reduction = tune(),
  sample_size = tune(),
  stop_iter = tune()
) |>
  set_engine("xgboost") |>
  set_mode("regression")

# workflow set from recipes and model
wf_sets <- workflow_set(
  preproc = recipes,
  models = list(xgb = xgb_spec)
)

# tuning control
ctrl <- finetune::control_sim_anneal(
  save_pred = TRUE,
  parallel_over = "everything",
  save_workflow = TRUE,
  verbose = TRUE
)

# tune all workflows
tuned_results <- workflow_map(
  wf_sets,
  fn = "tune_sim_anneal",
  control = ctrl,
  metrics = metric_set(rmse, rsq),
  resamples = folds,
  seed = 42
)

# stop future plan
future::plan(future::sequential)
```

The last step in this process is to fit some models that are doing far too much, considering they are ostensibly intended to compare the predictive power of two different features. I've fit and tuned six different XGBoost models, one each for squad value and staff costs across the three outcomes. Season and team have been included as additional features, similar to the original model[^MLM].

I won't bother walking through the models in detail. The goal isn't to go to great lengths to fit perfect models. I've done a little tuning just for the hell of it[^Fit], but the focus is on comparing the performance of the squad value and staff costs models.

Model performance, measured using root mean square error (RMSE) and R<sup>2</sup> is shown in @tbl-model-performance.

```{r}
#| label: eval-functions
#| code-fold: true
#| code-summary: 'Helper Functions Code (Click to Expand)'

# select the best parameters
select_best_model <- function(results, model_id) {
  results |>
    extract_workflow_set_result(model_id) |>
    select_best(metric = "rmse")
}

# finalize and refit on full training data
finalize_and_fit_model <- function(results, model_id, data_split) {
  best_params <- select_best_model(results, model_id)

  results |>
    extract_workflow(model_id) |>
    finalize_workflow(best_params) |>
    last_fit(split = data_split, metrics = metric_set(rmse, rsq))
}

# extract test performance metrics
get_test_metrics <- function(results, model_id, data_split) {
  finalize_and_fit_model(results, model_id, data_split) |>
    collect_metrics()
}
```

```{r}
#| label: best-params
#| include: false

# get best hyperparameters for each model
best_params <- purrr::map(
  tuned_results$wflow_id,
  ~ select_best_model(tuned_results, .x)
)
names(best_params) <- tuned_results$wflow_id

best_params
```

```{r}
#| label: tbl-model-performance
#| tbl-cap: Performance of XGBoost Models Predicting Bundesliga Outcomes
#| code-fold: true
#| code-summary: 'Table Code (Click to Expand)'

# get test performance for all models
summary_table <-
  tuned_results |>
  mutate(
    test_metrics = map(wflow_id, ~ get_test_metrics(tuned_results, .x, splits)),
    feature_set = if_else(
      stringr::str_detect(wflow_id, "_squad"),
      "Squad Value",
      "Staff Costs"
    ),
    outcome = case_when(
      stringr::str_starts(wflow_id, "pts") ~ "Points",
      stringr::str_starts(wflow_id, "gd") ~ "Goal Difference",
      stringr::str_starts(wflow_id, "xgd") ~ "xG Difference"
    ),
    outcome = forcats::fct(
      outcome,
      levels = c("Points", "Goal Difference", "xG Difference")
    )
  ) |>
  arrange(outcome) |>
  unnest(test_metrics) |>
  pivot_wider(names_from = .metric, values_from = .estimate) |>
  select(feature_set, outcome, rmse, rsq)

# display metrics table
summary_table |>
  gt(groupname_col = "feature_set", rowname_col = "outcome") |>
  cols_label(
    rmse = "RMSE",
    rsq = html("R<sup>2</sup>")
  ) |>
  fmt_number(
    columns = c(rmse, rsq),
    decimals = 2,
    drop_trailing_zeros = TRUE
  ) |>
  cols_align(align = "left", columns = outcome) |>
  cols_align(align = "center", columns = c(rmse, rsq)) |>
  tab_spanner(label = "Evaluation Metrics", columns = c(rmse, rsq)) |>
  tab_footnote(
    footnote = html(
      glue::glue(
        "Calculated using correlation (see ",
        "<a href='https://yardstick.tidymodels.org/reference/rsq.html'>",
        "documentation</a>)"
      )
    ),
    locations = cells_column_labels(columns = "rsq")
  ) |>
  tab_footnote(
    footnote = "Standardised using games played",
    locations = cells_stub(rows = everything())
  ) |>
  tab_style(
    style = list(cell_text(weight = "bold")),
    locations = cells_column_spanners()
  ) |>
  tab_style(
    style = list(cell_text(weight = "bold")),
    locations = cells_row_groups()
  ) |>
  tbl_theme()
```

@tbl-model-performance shows a similar pattern to the correlations in @tbl-correlation. The squad value models consistently outperform the staff costs models across both metrics, especially R<sup>2</sup>. It's worth noting that the models are tuned on RMSE, so the variance in R<sup>2</sup> across the two sets of models is possibly a function of this. However, there is a sizable increase in RMSE, too.

The consistency of this finding, plus the evidence in @tbl-team-difference that the difference between squad value and staff costs is partially a function of team quality, suggests that squad value has some performance bias baked in. I don't think this invalidates squad values as a proxy for investment in the squad, but it does demonstrate a limitation in this approach.

[^MLM]:

Some minor differences exist between these models and those I fit in my earlier blog post. These differences are primarily due to the flexibility of the original model's multilevel structure, which allowed me to do a little more.

[^Fit]:

I used this post as an excuse to play around with [**future**](https://future.futureverse.org) and [**furrr**](https://furrr.futureverse.org), so I ended up going to greater lengths to tune the models, but only as a way to make better use of parallel processing.

## How Reliable are Squad Values?

There is plenty of research that demonstrates the reliability of Transfermarkt's player market values (and by extension squad values) across a variety of contexts [@herm2014; @muller2017; @prockl2018; @smith2021; @coates2022; @james2022]. They are a decent approximation of player values on an open market [@transfermarkt2021], which makes them pretty handy for several different use cases. I think the evidence shown in this blog post suggests that a proxy for investment in squads is one of those use cases, but that conclusion does come with some caveats.

Given how [Transfermarkt's values are estimated](https://www.transfermarkt.com/market-value-definition/thread/forum/357/thread_id/3433), I think there will obviously be some performance bias. Historic squad values are a snapshot from previous seasons, and they appear to be an average across the season[^Values]. As a consequence, adjustments to player values due to performance will have some impact on squad values.

It's also worth noting that I'm using a small sample of data limited only to the Bundesliga[^Limitations], which reduces how much we can infer from this. Evidence shows that player values vary in predictive value by league [@muller2017; @coates2022], so findings based on a handful of seasons in a single league should be understood within their limited scope.

Still, I think the results support the idea that Transfermarkt's squad values are a reasonable proxy for squad spending. Regarding my model specifically, I think the structure of the model should help negate some of these issues, particularly the effects of partial pooling. Generally, though, squad value and staff costs are almost perfectly correlated. While the squad value models are consistently better, I don't think they are so different that it invalidates using squad value as a proxy.

Instead, I think it is something to be aware of if using squad values in this context. Every approach will have limitations, but if you can identify them, discuss them in your analysis, and even point to the specific ways they impact your model, you should be in a good place. With squad values, better the devil you know.

[^Values]:

I'm unsure how historic squad values are derived, but they don't appear to align with values at a specific point in the season, so I assume they are average. A workaround would be to recreate preseason squad values by scraping Transfermarkt's player values over time (shout out to [John Muller](https://johnspacemuller.com) for pointing this one out to me).

[^Limitations]:

And while I am confident that staff and squad costs will be roughly equivalent, this adds another layer of potential noise.

## Acknowledgments {.appendix}

Many thanks to [Ansgar Wolsing](https://bsky.app/profile/ansgarw.bsky.social) for pointing me to the staff costs data I used in this blog post.

Preview image by [Tobias Rehbein](https://unsplash.com/@tobiasrehbein) on [Unsplash](https://unsplash.com/photos/a-soccer-ball-sitting-on-top-of-a-lush-green-field-CZ_HwDtvEus).

## Support {.appendix}

If you enjoyed this blog post and would like to support my work, you can [buy me a coffee or a beer or give me a tip](https://www.buymeacoffee.com/paulj1989) as a thank you.
